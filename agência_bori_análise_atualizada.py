# -*- coding: utf-8 -*-
"""Agência BORI - Análise atualizada.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11TqryzajC9BbXZv1sUJwnu1E8eO0jdGF

# Módulos
"""

import json
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import random
import re
import requests
import string
from bs4 import BeautifulSoup
from google.cloud import bigquery
from google.cloud.bigquery.job import LoadJobConfig, WriteDisposition, CreateDisposition

!pip install dash gender-guesser-br itables

from dash import Dash, dash_table, dcc, html, Input, Output
from gender_guesser_br import Genero
from itables import init_notebook_mode
init_notebook_mode(all_interactive=True)

from google.colab import drive
drive.mount('/content/drive/')
folder = '/content/drive/MyDrive/AGENCIES/BORI/'

from google.colab import auth
auth.authenticate_user()
print('Authenticated')

"""# Agência BORI - Análise atualizada

## Interação inicial
"""

# Inicia o cliente BigQuery para interagir com os dados da BORI e do OpenAlex
bq_client = bigquery.Client(project='insyspo')

# Função utilizada para salvar novas tabelas no BigQuery. Elas serão salvas no meu banco de dados pessoal (userdb_thais_peixoto) e não no do
# projeto (projectdb_labincc), mas isso não afeta a análise. Se for do interesse de vocês, acho que a Germana pode me dar a permissão de
# escrita/edição no banco projectdb_labincc
def salva_tabela_bq(nome_tabela, dataframe):
  table_id = 'userdb_thais_peixoto.' + nome_tabela
  load_config = LoadJobConfig(create_disposition=CreateDisposition.CREATE_IF_NEEDED,
                              write_disposition=WriteDisposition.WRITE_TRUNCATE)
  job = bq_client.load_table_from_dataframe(
      dataframe, table_id, job_config=load_config
  )
  job.result()

# Commented out IPython magic to ensure Python compatibility.
# # Retorna todos os dados da tabela bori_full
# %%bigquery bori_full --project=insyspo
# 
# SELECT *
# FROM projectdb_labincc.bori_full;

"""## Correções

### Removendo linhas duplicadas
"""

# Resolvi verificar de novo a existência de PRs duplicados (que era o caso da planilha)
linhas_duplicadas = bori_full.loc[bori_full['Title_link'].duplicated()]
linhas_duplicadas

# Remove as linhas duplicadas (preservando a original)
for i in [365, 369]:
  bori_full.drop(i, inplace=True)

# A tabela agora tem 370 linhas, assim como a planilha antiga
len(bori_full)

"""### Preenchendo colunas vazias"""

# Teve o problema que mencionei de que as colunas category-link e entry-date estavam vazias. Pensei numa forma mais fácil de resolver
# a situação: como na planilha BoriPautas.xlsx ambas as colunas estavam completas, decidi unir os dados da planilha aos da tabela para
# suprir essa falta de dados

# Lê a planilha BoriPautas.xlsx
bori_pautas = pd.read_excel(folder+'BoriPautas.xlsx')

# Encontra as linhas duplicadas da planilha
linhas_duplicadas = bori_pautas.loc[bori_pautas['Title_link'].duplicated()]
linhas_duplicadas

# Remove as linhas duplicadas (preservando as originais)
for i in [10, 11, 12, 118]:
  bori_pautas.drop(i, inplace=True)

# A quantidade de linhas da planilha agora corresponde à quantidade de linhas da tabela
len(bori_pautas)

# Relaciona os dados da planilha e da tabela onde o link da BORI for o mesmo
links = bori_full['Title_link']

for link in links:
  categoria = ''.join(dict(bori_pautas.loc[bori_pautas['Title_link'].eq(link), 'category-link']).values())
  data = ''.join(dict(bori_pautas.loc[bori_pautas['Title_link'].eq(link), 'entry-date']).values())
  bori_full.loc[bori_full['Title_link'].eq(link), 'category-link'] = categoria
  bori_full.loc[bori_full['Title_link'].eq(link), 'entry-date'] = data

# Agora as colunas estão preenchidas
bori_full.head()

"""### Corrigindo alguns detalhes"""

# Assim como na planilha, verifiquei se o conteúdo de Title seria igual ao conteúdo de Headline na tabela: retornou verdadeiro
bori_full['Title'].equals(bori_full['Headline'])

# Remove a coluna Headline da tabela (não vejo a necessidade de duas colunas iguais)
bori_full = bori_full.drop(columns=['Headline'])

# Eu suspeitei que talvez as colunas ficaram vazias devido aos seus nomes (o ideal seria, por exemplo, category_link, sem hífen), então decidi
# substituí-los
# category-link -> category (não se trata de uma coluna com links, então removi o "-link")
# entry-date -> entry_date
bori_full = bori_full.rename(columns={'category-link': 'category', 'entry-date': 'entry_date'})

"""### Corrigindo os DOIs"""

# Procurei os DOIs fora do padrão, mas só retornaram esses três. Como é um problema simples, decidi resolver manualmente (célula abaixo)
bori_full['DOI'] = bori_full['DOI'].astype(str)
links = list(bori_full.loc[(~bori_full['DOI'].str.contains('https://doi.org/')) & (~bori_full['DOI'].str.contains('None')), 'DOI'])
links

# O primeiro DOI estava quebrado, então não deu pra recuperar. Decidi remover da tabela
bori_full.loc[bori_full['DOI'].eq('https://dx.doi.org/10.1098/'), 'DOI'] = ''

# O segundo era um link do ORCID que levava a um DOI, então fiz a substituição de um pelo outro
bori_full.loc[bori_full['DOI'].eq('https://orcid.org/0000-0001-8906-9714'), 'DOI'] = 'https://doi.org/10.12660/cgpc.v28.88602.84529'

# O terceiro levava ao SciELO, lá tinha o DOI correto
bori_full.loc[bori_full['DOI'].eq('http://dx.doi.org/10.1590/1809-4422asoc20210056vu2022L1AO'), 'DOI'] = 'https://doi.org/10.1590/1809-4422asoc20210056vu2022L1AO'

# Outro problema com os DOIs é que alguns estavam com caracteres especiais ou espaços em branco. Também tinham alguns com caracteres maiúsculos,
# o que atrapalhava a correspondência com os dados do OpenAlex (onde todos os DOIs têm apenas caracteres minúsculos). Corrigi esses
# problemas com o código abaixo
dois = list(bori_full['DOI'])

for doi in dois:
  bori_full.loc[bori_full['DOI'].eq(doi), 'DOI'] = doi.lower().strip()

# Por fim, mais uma situação que percebi ao trabalhar nas demais seções: havia dois PRs diferentes com o mesmo DOI
dois_duplicados = bori_full.loc[(bori_full['DOI'].duplicated()) & (~bori_full['DOI'].str.contains('none')), 'DOI']
dois_duplicados

# Procurando pelo DOI retornado acima na tabela, vemos dois PRs diferentes
bori_full.loc[bori_full['DOI'].eq('https://doi.org/10.1590/0102-311xpt255621')]

# Acessando o link de cada um, vi que o primeiro não possui DOI, e que o DOI informado pertence somente ao segundo PR. Por isso, removi o DOI
# do primeiro PR
bori_full.loc[bori_full['Title_link'].eq('https://abori.com.br/ambiente/restauracao-de-areas-desmatadas-depende-de-acoes-que-envolvem-biodiversidade-e-clima/'), 'DOI'] = ''

"""### Recuperando o conteúdo dos PRs"""

# Ao trabalhar na seção "Autores citados", reparei que cada linha continha apenas parte do conteúdo do PR correspondente, sendo
# sempre um pequeno trecho do mesmo terminando com reticências. Então decidi recuperar novamente o conteúdo de todos os PRs.
# Deixei esse trecho comentado porque demorou 13 minutos pra executar.

# links = list(bori_full['Title_link'])

# link_post = dict()
# for url in links:
#   response = requests.get(url)
#   soup = BeautifulSoup(response.content, 'html.parser')
#   post = soup.find('div', {'class': 'entry-content'}).text
#   post = post.replace('\n', ' ')
#   link_post[url] = post

# for key in link_post:
#   bori_full.loc[bori_full['Title_link'].eq(key), 'post'] = link_post[key]

# Salva os dados corrigidos no BigQuery (chamei a tabela de bori_latest).
# Deixei comentado pra não perder as correções já feitas.
# salva_tabela_bq('bori_latest', bori_full)

"""## Completude das colunas"""

# Commented out IPython magic to ensure Python compatibility.
# # Retorna todos os dados da nova tabela bori_latest
# %%bigquery bori_latest --project=insyspo
# 
# SELECT *
# FROM userdb_thais_peixoto.bori_latest;

# Calcula o número de células devidamente preenchidas em cada coluna
n_linhas = dict()

colunas = ['Title', 'category', 'entry_date', 'post', 'Local']
for coluna in colunas:
  n_linhas[coluna] = len(bori_latest.loc[bori_latest[coluna].notnull(), coluna])

colunas = ['Title_link', 'Thumbnail']
for coluna in colunas:
  bori_latest[coluna] = bori_latest[coluna].astype(str)
  n_linhas[coluna] = len(bori_latest.loc[bori_latest[coluna].str.contains('https://abori.com.br/'), coluna])

n_linhas['DOI'] = len(bori_latest.loc[bori_latest['DOI'].str.contains('https://doi.org/'), 'DOI'])

n_linhas_df = pd.DataFrame(n_linhas.items())
n_linhas_df.columns = ['Coluna', 'Nº de células']
n_linhas_df.sort_values('Nº de células', inplace=True)
n_linhas_df

fig = px.bar(n_linhas_df,
             x="Nº de células",
             y="Coluna",
             orientation='h',
             color_discrete_sequence=[px.colors.qualitative.Plotly[0]],
             title='bori_full - Completude das colunas',
             text_auto=True)
fig.update_layout(yaxis={'categoryorder':'total descending'})
fig.show()

# Calcula o percentual de células devidamente preenchidas em cada coluna (considerando o máximo de 370)
p_linhas = dict()

for key in n_linhas:
  p_linhas[key] = round((n_linhas[key]/370)*100, 2)

p_linhas_df = pd.DataFrame(p_linhas.items())
p_linhas_df.columns = ['Coluna', 'Percentual']
p_linhas_df.sort_values('Percentual', inplace=True)
p_linhas_df

fig = px.bar(p_linhas_df,
             x="Percentual",
             y="Coluna",
             orientation='h',
             color_discrete_sequence=[px.colors.qualitative.Plotly[1]],
             title='bori_full - Completude das colunas (percentual)',
             text_auto=True)
fig.update_layout(yaxis={'categoryorder':'total descending'})
fig.show()

"""## Número/Percentual de DOIs"""

# A quantidade de DOIs únicos é igual à quantidade total de DOIs da planilha, ou seja, não há repetições
dois_unicos = bori_latest.loc[bori_latest['DOI'].str.contains('https://doi.org/'), 'DOI'].unique()
len(dois_unicos)

# O percentual de DOIs permanece o mesmo do gráfico anterior
p_dois = round((len(dois_unicos)/370)*100, 2)
p_dois

analise_quantidade = {'PRs com DOIs únicos': len(dois_unicos),
                      'PRs sem DOI': len(bori_latest) - len(dois_unicos)}
analise_quantidade = pd.DataFrame(analise_quantidade.items())
analise_quantidade.columns = ['Análise', 'Quantidade']
analise_quantidade

fig = px.pie(analise_quantidade,
             values='Quantidade',
             names='Análise',
             color_discrete_sequence=[px.colors.qualitative.Plotly[7], px.colors.qualitative.Plotly[2]],
             title='BORI - Associação press release/DOI')
fig.show()

"""## PRs por mês"""

# Relaciona o título do PR ao mês em que foi publicado
titulos = bori_latest['Title']
titulo_mes = dict()

for titulo in titulos:
  entry_date = str(bori_latest.loc[bori_latest['Title'].eq(titulo), 'entry_date'])
  entry_date = entry_date.split()
  entry_date = entry_date[3]
  titulo_mes[titulo] = entry_date

titulo_mes = pd.DataFrame(titulo_mes.items())
titulo_mes.columns = ['Título', 'Mês']

# Calcula quantas publicações ocorreram em cada mês
meses = titulo_mes['Mês'].unique()
mes_quantidade_prs = dict()

for mes in meses:
  mes_quantidade_prs[mes] = len(titulo_mes.loc[titulo_mes['Mês'].eq(mes), 'Título'])

mes_quantidade_prs = pd.DataFrame(mes_quantidade_prs.items())
mes_quantidade_prs.columns = ['Mês', 'Nº de publicações']
mes_quantidade_prs.sort_values('Nº de publicações', ascending=False, inplace=True)
mes_quantidade_prs

fig = px.bar(mes_quantidade_prs,
             x="Nº de publicações",
             y="Mês",
             orientation='h',
             color_discrete_sequence=[px.colors.qualitative.Plotly[4]],
             title='BORI - Número de press releases por mês',
             text_auto=True)
fig.update_layout(yaxis={'categoryorder':'total ascending'})
fig.show()

"""## DOIs por mês"""

# Relaciona o DOI ao mês em que o PR correspondente foi publicado
dois = list(bori_latest.loc[bori_latest['DOI'].str.contains('https://doi.org/'), 'DOI'])
doi_mes = dict()

for doi in dois:
  entry_date = str(bori_latest.loc[bori_latest['DOI'].eq(doi), 'entry_date'])
  entry_date = entry_date.split()
  entry_date = entry_date[3]
  doi_mes[doi] = entry_date

doi_mes = pd.DataFrame(doi_mes.items())
doi_mes.columns = ['DOI', 'Mês']

# Calcula a quantidade de DOIs para cada mês
meses = doi_mes['Mês'].unique()
mes_quantidade_dois = dict()

for mes in meses:
  mes_quantidade_dois[mes] = len(doi_mes.loc[doi_mes['Mês'].eq(mes), 'DOI'])

mes_quantidade_dois = pd.DataFrame(mes_quantidade_dois.items())
mes_quantidade_dois.columns = ['Mês', 'Nº de publicações']
mes_quantidade_dois.sort_values('Nº de publicações', ascending=False, inplace=True)
mes_quantidade_dois

fig = px.bar(mes_quantidade_dois,
             x="Nº de publicações",
             y="Mês",
             orientation='h',
             color_discrete_sequence=[px.colors.qualitative.Plotly[5]],
             title='BORI - Número de DOIs por mês',
             text_auto=True)
fig.update_layout(yaxis={'categoryorder':'total ascending'})
fig.show()

"""## Publicações por categoria (BORI)"""

# Calcula quantas publicações existem por categoria
categorias = bori_latest['category'].unique()
categoria_quantidade = dict()

for categoria in categorias:
  categoria_quantidade[categoria] = len(bori_latest.loc[bori_latest['category'].eq(categoria), 'Title'])

categoria_quantidade = pd.DataFrame(categoria_quantidade.items())
categoria_quantidade.columns = ['Categoria', 'Nº de publicações']
categoria_quantidade.sort_values('Nº de publicações', ascending=False, inplace=True)
categoria_quantidade

fig = px.bar(categoria_quantidade,
             x="Nº de publicações",
             y="Categoria",
             orientation='h',
             color_discrete_sequence=[px.colors.qualitative.Plotly[6]],
             title='BORI - Número de publicações por categoria',
             text_auto=True)
fig.update_layout(autosize=False,
                  height=1100,
                  width=1265,
                  yaxis={'categoryorder':'total ascending'})
fig.show()

"""## Publicações sobre COVID-19"""

# Calcula quantas publicações envolvem o tema COVID-19
posts = bori_latest['post']
tema_quantidade = {'COVID-19': 0, 'Outros': 0}
titulo_verificado = dict()
palavras_chave = ['Covid',
                  'COVID-19',
                  'Coronavirus',
                  'Novel coronavirus',
                  'SARS-CoV-2',
                  'Covid-19 pandemic',
                  'the pandemic',
                  'epidemic',
                  'pandemia',
                  'epidemia']

for post in posts:
  titulo = ''.join(dict(bori_latest.loc[(bori_latest['post'].eq(post)), 'Title']). values())
  post = post.lower()
  for palavra_chave in palavras_chave:
    palavra_chave = palavra_chave.lower()
    if titulo not in titulo_verificado.keys() and palavra_chave in post:
      tema_quantidade['COVID-19'] += 1
      titulo_verificado[titulo] = True

tema_quantidade['Outros'] = len(posts) - tema_quantidade['COVID-19']

tema_quantidade_df = pd.DataFrame(tema_quantidade.items())
tema_quantidade_df.columns = ['Tema', 'Nº de publicações']
tema_quantidade_df.sort_values('Nº de publicações', inplace=True)
tema_quantidade_df

fig = px.pie(tema_quantidade_df,
             values='Nº de publicações',
             names='Tema',
             color_discrete_sequence=[px.colors.qualitative.Pastel[5], px.colors.qualitative.Pastel[9]],
             title='BORI - Publicações sobre COVID-19')
fig.show()

"""## Publicações sobre COVID-19 por ano"""

# Relaciona o título do PR ao ano em que foi publicado
titulos = bori_latest['Title']
titulo_ano = dict()

for titulo in titulos:
  ano = str(bori_latest.loc[bori_latest['Title'].eq(titulo), 'entry_date'])
  ano = ano.split()
  ano = ano[5]
  titulo_ano[titulo] = ano

titulo_ano = pd.DataFrame(titulo_ano.items())
titulo_ano.columns = ['Título', 'Ano']

# Calcula quantas publicações envolvem cada tema por ano
posts = bori_latest['post']
titulos = bori_latest['Title']
titulo_verificado = dict()

palavras_chave = ['Covid',
                  'COVID-19',
                  'Coronavirus',
                  'Novel coronavirus',
                  'SARS-CoV-2',
                  'Covid-19 pandemic',
                  'the pandemic',
                  'epidemic',
                  'pandemia',
                  'epidemia']

anos = titulo_ano['Ano'].unique()
ano_tema = pd.DataFrame(columns = ['Ano', 'COVID-19', 'Outros'])
for ano in anos:
  ano_tema.loc[len(ano_tema.index)] = [ano, 0, 0]

for post in posts:
  titulo = ''.join(dict(bori_latest.loc[(bori_latest['post'].eq(post)), 'Title']). values())
  ano = ''.join(dict(titulo_ano.loc[titulo_ano['Título'].eq(titulo), 'Ano']). values())
  post = post.lower()
  for palavra_chave in palavras_chave:
    palavra_chave = palavra_chave.lower()
    if titulo not in titulo_verificado.keys() and palavra_chave in post:
      ano_tema.loc[ano_tema['Ano'].eq(ano), 'COVID-19'] += 1
      titulo_verificado[titulo] = True

for titulo in titulos:
  ano = ''.join(dict(titulo_ano.loc[titulo_ano['Título'].eq(titulo), 'Ano']). values())
  if titulo not in titulo_verificado.keys():
    ano_tema.loc[ano_tema['Ano'].eq(ano), 'Outros'] += 1
    titulo_verificado[titulo] = True

ano_tema.sort_values('Ano', inplace=True)
ano_tema

fig = go.Figure(data=[
    go.Bar(name='COVID-19',
           x=ano_tema['Ano'],
           y=ano_tema['COVID-19'],
           marker_color=px.colors.qualitative.Pastel[9],
           text=ano_tema['COVID-19']),
    go.Bar(name='Outros',
           x=ano_tema['Ano'],
           y=ano_tema['Outros'],
           marker_color=px.colors.qualitative.Pastel[5],
           text=ano_tema['Outros'])
])
fig.update_layout(barmode='group',
                  title="Publicações sobre COVID-19 por ano",)
fig.show()

"""## Publicações indexadas no SciELO"""

# Calcula quantas publicações são indexadas no SciELO.
# Deixei comentado porque esse código demora uns 10 minutos ou mais pra executar

# links = list(bori_full['Title_link'])

# link_indexado = dict()
# for link in links:
#   response = requests.get(link)
#   soup = BeautifulSoup(response.content, 'html.parser')
#   conteudo = soup.find('div', {'class': 'entry-content'})
#   children = conteudo.findChildren('img')
#   for child in children:
#     if link not in link_indexado.keys() and 'index-scielo' in str(child):
#       link_indexado[link] = True
#       print(link)

# Salva uma tabela de nome "pubs_indexadas_scielo" no BigQuery, com os links (da Agência BORI) de todas as publicações indexadas.
# Fiz isso pra não ter que ficar rodando o código toda vez

# pubs_indexadas_scielo = pd.DataFrame(link_indexado.keys())
# pubs_indexadas_scielo.columns = ['link_bori']
# salva_tabela_bq('pubs_indexadas_scielo', pubs_indexadas_scielo)

# Commented out IPython magic to ensure Python compatibility.
# # Retorna todos os links dos PRs indexados
# %%bigquery pubs_indexadas_scielo --project=insyspo
# 
# SELECT *
# FROM userdb_thais_peixoto.pubs_indexadas_scielo;

indexacao_quantidade = {'Indexadas': len(pubs_indexadas_scielo),
                        'Não indexadas': len(bori_latest)-len(pubs_indexadas_scielo)}
indexacao_quantidade = pd.DataFrame(indexacao_quantidade.items())
indexacao_quantidade.columns = ['Indexação SciELO', 'Nº de publicações']
indexacao_quantidade.sort_values('Nº de publicações', inplace=True)
indexacao_quantidade

fig = px.pie(indexacao_quantidade,
             values='Nº de publicações',
             names='Indexação SciELO',
             color_discrete_sequence=[px.colors.qualitative.Pastel1[7], px.colors.qualitative.Set1[7]],
             title='BORI - Publicações indexadas no SciELO')
fig.show()

"""## Relacionando com os dados do OpenAlex

### Interação inicial
"""

# Commented out IPython magic to ensure Python compatibility.
# # Relaciona os DOIs da tabela com os DOIs do OpenAlex
# %%bigquery bori_openalex --project=insyspo
# 
# SELECT bori_latest.DOI, bori_latest.Title_link, works.doi
# FROM publicdb_openalex_2023_08_rm.works AS works
# JOIN userdb_thais_peixoto.bori_latest AS bori_latest
# ON bori_latest.DOI = works.doi;

# 124 dos DOIs da tabela existem no banco de dados do OpenAlex, tornando possível a recuperação de algumas informações adicionais
bori_openalex.columns = ['DOI - BORI', 'Link BORI', 'DOI - OpenAlex']
len(bori_openalex)

"""### DOIs perdidos"""

# Retorna os DOIs que não foram encontrados no OpenAlex
dois_encontrados = list(bori_openalex['DOI - BORI'])
dois_total = list(bori_latest['DOI'])
dois_perdidos = list()

for doi in dois_total:
  if doi not in dois_encontrados and 'https://doi.org/' in doi:
    dois_perdidos.append(doi)

len(dois_perdidos)

dois_perdidos = pd.DataFrame(dois_perdidos)
dois_perdidos.columns = ['DOI']
dois_perdidos

"""### Instituições por região"""

# Commented out IPython magic to ensure Python compatibility.
# # A partir daqui, todas as análises são feitas sobre 124 dos 130 DOIs. Isso também implica em 124 dos 370 PRs
# 
# # Retorna as instituições e alguns outros dados associados a cada uma (tabela abaixo)
# %%bigquery bori_instituicoes --project=insyspo
# 
# SELECT institutions.display_name, institutions.ror, institutions.geonames_city_id, COUNT(DISTINCT(bori_latest.DOI)) as n_pubs
# 
# FROM publicdb_openalex_2023_08_rm.works AS works
# JOIN userdb_thais_peixoto.bori_latest AS bori_latest
# ON bori_latest.DOI = works.doi
# JOIN publicdb_openalex_2023_08_rm.works_authorships AS works_authorships
# ON works.id = works_authorships.work_id
# JOIN publicdb_openalex_2023_08_rm.institutions AS institutions
# ON works_authorships.institution_id = institutions.id
# 
# GROUP BY institutions.display_name, institutions.ror, institutions.geonames_city_id
# ORDER BY n_pubs DESC;

bori_instituicoes.columns = ['Instituição', 'ROR', 'GeoNames ID', 'Nº de publicações']
bori_instituicoes

# Descobri uma API do GeoNames que permite encontrar os estados de cada instituição (além de outros dados).
# Esse trecho demora cerca de 1 minuto pra executar. O limite da API é de 1000 requisições/hora (esse trecho faz 293)
rors = list(bori_instituicoes['ROR'])
estados = [ 'Acre', 'Alagoas', 'Amapá', 'Amazonas', 'Bahia', 'Ceará', 'Distrito Federal', 'Espírito Santo', 'Goiás', 'Maranhão', 'Mato Grosso do Sul',
            'Mato Grosso', 'Minas Gerais', 'Pará', 'Paraíba', 'Paraná', 'Pernambuco', 'Piauí', 'Rio de Janeiro', 'Rio Grande do Norte',
            'Rio Grande do Sul', 'Rondônia', 'Roraima', 'Santa Catarina', 'São Paulo', 'Sergipe', 'Tocantins', 'Federal District']
ror_estado_brasil = dict()
ror_estado_internacional = dict()

for ror in rors:
  id = ''.join(dict(bori_instituicoes.loc[bori_instituicoes['ROR'].eq(ror), 'GeoNames ID']).values())
  response = requests.get('http://api.geonames.org/get?username=thaiscsp&country=BR&maxRows=1&style=full&geonameId='+id)
  soup = BeautifulSoup(response.content, 'lxml')
  estado = soup.find('adminname1').getText()
  if estado in estados:
    ror_estado_brasil[ror] = estado
    print('Brasil / '+ ror +': '+ estado)
  else:
    ror_estado_internacional[ror] = estado
    print('Internacional / '+ ror +': '+ estado)

print('--- Fim ---')

# Alguns RORs retornaram estados brasileiros...
ror_estado_brasil = pd.DataFrame(ror_estado_brasil.items())
ror_estado_brasil.columns = ['ROR', 'Estado']
ror_estado_brasil

# ... outros retornaram locais internacionais
ror_estado_internacional = pd.DataFrame(ror_estado_internacional.items())
ror_estado_internacional.columns = ['ROR', 'Estado']
ror_estado_internacional

# Conta quantas instituições existem em cada região
rors = list(ror_estado_brasil['ROR'])
regiao_quantidade = { 'Norte': 0,
                      'Nordeste': 0,
                      'Centro-Oeste': 0,
                      'Sudeste': 0,
                      'Sul': 0}
norte = ['Amazonas', 'Acre', 'Rondônia', 'Roraima', 'Amapá', 'Pará', 'Tocantins']
nordeste = ['Maranhão', 'Piauí', 'Rio Grande do Norte', 'Ceará', 'Paraíba', 'Bahia', 'Pernambuco', 'Alagoas', 'Sergipe']
centro_oeste = ['Goiás', 'Mato Grosso', 'Mato Grosso do Sul', 'Federal District']
sudeste = ['Minas Gerais', 'Espírito Santo', 'Rio de Janeiro', 'São Paulo']

for ror in rors:
  estado = ''.join(dict(ror_estado_brasil.loc[ror_estado_brasil['ROR'].eq(ror), 'Estado']).values())
  if estado in norte:
    regiao_quantidade['Norte'] += 1
  elif estado in nordeste:
    regiao_quantidade['Nordeste'] += 1
  elif estado in centro_oeste:
    regiao_quantidade['Centro-Oeste'] += 1
  elif estado in sudeste:
    regiao_quantidade['Sudeste'] += 1
  else:
    regiao_quantidade['Sul'] += 1

regiao_quantidade = pd.DataFrame(regiao_quantidade.items())
regiao_quantidade.columns = ['Região', 'Nº de instituições']
regiao_quantidade.sort_values('Nº de instituições', ascending=False, inplace=True)
regiao_quantidade

fig = px.bar(regiao_quantidade,
             x="Nº de instituições",
             y="Região",
             orientation='h',
             color_discrete_sequence=[px.colors.qualitative.Plotly[9]],
             title='BORI - Número de instituições por região',
             text_auto=True)
fig.update_layout(yaxis={'categoryorder':'total ascending'})
fig.show()

"""### Publicações por área do conhecimento (OpenAlex)"""

# Commented out IPython magic to ensure Python compatibility.
# # Recupera as áreas do conhecimento e o número de publicações associadas a cada uma
# %%bigquery bori_areas --project=insyspo
# 
# SELECT concepts.display_name, COUNT(DISTINCT(bori_latest.DOI)) as n_pubs
# 
# FROM userdb_thais_peixoto.bori_latest AS bori_latest
# JOIN publicdb_openalex_2023_08_rm.works AS works
# ON bori_latest.DOI = works.doi
# JOIN publicdb_openalex_2023_08_rm.works_concepts AS works_concepts
# ON works.id = works_concepts.work_id
# JOIN publicdb_openalex_2023_08_rm.concepts AS concepts
# ON works_concepts.concept_id = concepts.id
# 
# WHERE concepts.level = 0
# GROUP BY concepts.display_name
# ORDER BY n_pubs;

# Essas são as áreas de nível 0, mais abrangentes; ainda existem outras mais específicas, com níveis que vão de 1 a 5. Se precisarem posso
# fazer para os outros níveis
bori_areas.columns = ['Área do conhecimento', 'Nº de publicações']
bori_areas.sort_values('Nº de publicações', ascending=False, inplace=True)
bori_areas

fig = px.bar(bori_areas,
             x="Nº de publicações",
             y="Área do conhecimento",
             orientation='h',
             color_discrete_sequence=[px.colors.qualitative.Pastel1[0]],
             title='BORI - Número de publicações por área do conhecimento',
             text_auto=True)
fig.update_layout(autosize=False,
                  height=700,
                  width=1265,
                  yaxis={'categoryorder':'total ascending'})
fig.show()

"""### Agrupamento de áreas do conhecimento"""

# Agrupa as áreas mais específicas (do gráfico acima) nas 6 grandes áreas sugeridas
areas = list(bori_areas['Área do conhecimento'])

bori_agrupamento = {'Ciências biológicas e da saúde': 0,
                    'Ciências da terra e meio ambiente': 0,
                    'Ciências humanas': 0,
                    'Ciências sociais aplicadas': 0,
                    'Ciências exatas e engenharias': 0,
                    'Artes': 0}

ciencias_biologicas = ['Biology', 'Medicine']
ciencias_da_terra = ['Environmental science', 'Geography', 'Geology']
ciencias_humanas = ['Sociology', 'Philosophy', 'Political science', 'Psychology']
ciencias_sociais = ['Economics', 'Business']
ciencias_exatas = ['Chemistry', 'Computer science', 'Engineering', 'Physics', 'Mathematics', 'Materials science']

for area in areas:
  n_pubs = int(bori_areas.loc[bori_areas['Área do conhecimento'].eq(area), 'Nº de publicações'])
  if area in ciencias_biologicas:
    bori_agrupamento['Ciências biológicas e da saúde'] += n_pubs
  elif area in ciencias_da_terra:
    bori_agrupamento['Ciências da terra e meio ambiente'] += n_pubs
  elif area in ciencias_humanas:
    bori_agrupamento['Ciências humanas'] += n_pubs
  elif area in ciencias_sociais:
    bori_agrupamento['Ciências sociais aplicadas'] += n_pubs
  elif area in ciencias_exatas:
    bori_agrupamento['Ciências exatas e engenharias'] += n_pubs
bori_agrupamento['Artes'] = int(bori_areas.loc[bori_areas['Área do conhecimento'].eq('Art'), 'Nº de publicações'])

bori_agrupamento = pd.DataFrame(bori_agrupamento.items())
bori_agrupamento.columns = ['Área do conhecimento (geral)', 'Nº de publicações']
bori_agrupamento.sort_values('Nº de publicações', ascending=False, inplace=True)
bori_agrupamento

fig = px.bar(bori_agrupamento,
             x="Nº de publicações",
             y="Área do conhecimento (geral)",
             orientation='h',
             color_discrete_sequence=[px.colors.qualitative.Alphabet[18]],
             title='BORI - Número de publicações por área do conhecimento (geral)',
             text_auto=True)
fig.update_layout(yaxis={'categoryorder':'total ascending'})
fig.show()

"""### Publicações de acesso aberto (considerando todos os PRs)"""

# Commented out IPython magic to ensure Python compatibility.
# # Recupera todas as publicações de acesso aberto encontradas no OpenAlex
# %%bigquery bori_oa --project=insyspo
# 
# SELECT bori_latest.DOI, bori_latest.Title_link, oa.is_oa
# 
# FROM userdb_thais_peixoto.bori_latest AS bori_latest
# JOIN publicdb_openalex_2023_08_rm.works AS works
# ON bori_latest.DOI = works.doi
# JOIN publicdb_openalex_2023_08_rm.works_best_oa_location AS oa
# ON works.id = oa.id;

# Commented out IPython magic to ensure Python compatibility.
# # Recupera as publicações indexadas no SciELO (que são de acesso aberto)
# %%bigquery bori_pubs_scielo --project=insyspo
# 
# SELECT *
# FROM userdb_thais_peixoto.pubs_indexadas_scielo;

# Reúne os resultados e elimina as duplicações, resultando em 120 publicações de acesso aberto
bori_oa_total  = pd.concat([bori_oa['Title_link'], bori_pubs_scielo['link_bori']])
bori_oa_total = set(bori_oa_total)
len(bori_oa_total)

# 240 dos PRs têm tipo de acesso indeterminado
links_total = list(bori_latest['Title_link'])
links_openalex = list(bori_openalex['Link BORI'])
links_scielo = list(bori_pubs_scielo['link_bori'])
bori_desconhecidos = list()

for link in links_total:
  if link not in links_openalex and link not in links_scielo:
    bori_desconhecidos.append(link)

len(bori_desconhecidos)

# Com isso restam 10 PRs de acesso fechado (120 + 240 + 10 = 370)
bori_fechados = len(links_total) - (len(bori_desconhecidos) + len(bori_oa_total))
bori_fechados

acesso_quantidade = {'Acesso aberto': len(bori_oa_total),
                     'Acesso fechado': bori_fechados,
                     'Desconhecido': len(bori_desconhecidos)}
acesso_quantidade = pd.DataFrame(acesso_quantidade.items())
acesso_quantidade.columns = ['Tipo de acesso', 'Nº de publicações']
acesso_quantidade.sort_values('Nº de publicações', ascending=False, inplace=True)
acesso_quantidade

fig = px.pie(acesso_quantidade,
             values='Nº de publicações',
             names='Tipo de acesso',
             color_discrete_sequence=[px.colors.qualitative.Pastel2[0], px.colors.qualitative.Dark2[0], px.colors.qualitative.Set2[0]],
             title='BORI - Número de publicações de acesso aberto')
fig.show()

"""### Publicações de acesso aberto (considerando apenas as que têm DOI)"""

# Commented out IPython magic to ensure Python compatibility.
# # Recupera todas as publicações de acesso aberto encontradas no OpenAlex
# %%bigquery bori_oa --project=insyspo
# 
# SELECT bori_latest.DOI, bori_latest.Title_link, oa.is_oa
# 
# FROM userdb_thais_peixoto.bori_latest AS bori_latest
# JOIN publicdb_openalex_2023_08_rm.works AS works
# ON bori_latest.DOI = works.doi
# JOIN publicdb_openalex_2023_08_rm.works_best_oa_location AS oa
# ON works.id = oa.id;

# Dos 124 DOIs, 98 são de acesso aberto
len(bori_oa)

acesso_quantidade = {'Acesso aberto': len(bori_oa),
                     'Acesso fechado': len(bori_openalex) - len(bori_oa)}
acesso_quantidade = pd.DataFrame(acesso_quantidade.items())
acesso_quantidade.columns = ['Tipo de acesso', 'Nº de publicações']
acesso_quantidade.sort_values('Nº de publicações', ascending=False, inplace=True)
acesso_quantidade

fig = px.pie(acesso_quantidade,
             values='Nº de publicações',
             names='Tipo de acesso',
             color_discrete_sequence=[px.colors.qualitative.Dark2[0], px.colors.qualitative.Pastel2[0]],
             title='BORI - Número de publicações de acesso aberto')
fig.show()

"""### Publicações de acesso aberto (com DOI) x Publicações indexadas no SciELO"""

# Recuperando os valores dos gráficos anteriores
indexadas = int(indexacao_quantidade.loc[indexacao_quantidade['Indexação SciELO'].eq('Indexadas'), 'Nº de publicações'])
acesso_aberto = int(acesso_quantidade.loc[acesso_quantidade['Tipo de acesso'].eq('Acesso aberto'), 'Nº de publicações'])
nao_indexadas = int(indexacao_quantidade.loc[indexacao_quantidade['Indexação SciELO'].eq('Não indexadas'), 'Nº de publicações'])
acesso_fechado = int(acesso_quantidade.loc[acesso_quantidade['Tipo de acesso'].eq('Acesso fechado'), 'Nº de publicações'])

# Criando a comparação entre o tipo de acesso e a indexação no SciELO
bori_comparacao = {'Indexadas': indexadas,
                   'Acesso aberto': acesso_aberto,
                   'Não indexadas': nao_indexadas,
                   'Acesso fechado': acesso_fechado}

bori_comparacao = pd.DataFrame(bori_comparacao.items())
bori_comparacao.columns = ['Análise', 'Nº de publicações']
bori_comparacao

colors = [px.colors.qualitative.Set3[9],
          px.colors.qualitative.Set3[9],
          px.colors.qualitative.Pastel1[3],
          px.colors.qualitative.Pastel1[3]]

fig = go.Figure(data=[
    go.Bar(x = bori_comparacao['Nº de publicações'],
           y = bori_comparacao['Análise'],
           orientation='h',
           marker_color=colors,
           text=bori_comparacao['Nº de publicações']
)])
fig.update_layout(yaxis=dict(autorange="reversed"),
                  title='BORI - Publicações de acesso aberto x Publicações indexadas no SciELO')

"""### Autores citados por posição"""

# Commented out IPython magic to ensure Python compatibility.
# # Recupera os autores de cada publicação e algumas outras informações (tabela abaixo)
# %%bigquery bori_autores --project=insyspo
# 
# SELECT DISTINCT authors.display_name, works_authorships.author_position, bori_latest.DOI, bori_latest.Title_link
# 
# FROM userdb_thais_peixoto.bori_latest AS bori_latest
# JOIN publicdb_openalex_2023_08_rm.works AS works
# ON bori_latest.DOI = works.doi
# JOIN publicdb_openalex_2023_08_rm.works_authorships AS works_authorships
# ON works.id = works_authorships.work_id
# JOIN publicdb_openalex_2023_08_rm.authors AS authors
# ON works_authorships.author_id = authors.id;

bori_autores.columns = ['Nome', 'Posição', 'DOI', 'Link BORI']
bori_autores

# Procura pelos autores citados nos PRs. O autor é considerado citado se for encontrado o padrão "Primeiro Nome (...) Sobrenome"
autores_citados = pd.DataFrame(columns = ['Nome', 'Posição', 'DOI', 'Link BORI'])

for indice, linha in bori_autores.iterrows():
  nome_completo = linha['Nome']
  posicao = linha['Posição']
  doi = linha['DOI']
  link = linha['Link BORI']
  conteudo = ''.join(dict(bori_latest.loc[bori_latest['Title_link'].eq(link), 'post']).values())

  nome_completo = string.capwords(nome_completo)
  nome_completo = nome_completo.split()
  if re.search(r'' +nome_completo[0]+ '.*?' +nome_completo[-1], conteudo):
    nome_completo = ' '.join(nome_completo)
    autores_citados.loc[len(autores_citados.index)] = [nome_completo, posicao, doi, link]
    print(nome_completo+ ' , ' +posicao+ ' / ' +link)

print('--- Fim ---')

# Calcula o número de autores para cada posição
posicao_quantidade = {'first': 0,
                      'middle': 0,
                      'last': 0}

for indice, linha in autores_citados.iterrows():
  posicao_quantidade[linha['Posição']] += 1

posicao_quantidade = pd.DataFrame(posicao_quantidade.items())
posicao_quantidade.columns = ['Posição', 'Nº de autores']
posicao_quantidade

fig = px.pie(posicao_quantidade,
             values='Nº de autores',
             names='Posição',
             color_discrete_sequence=[px.colors.qualitative.Dark2[4], px.colors.qualitative.Set2[4], px.colors.qualitative.Pastel2[4]],
             title='BORI - Número de autores citados por posição')
fig.show()

"""### Autores citados por gênero"""

# Tentei usar uma API para encontrar o gênero dos autores com base no primeiro nome e no sobrenome. Também consegui especificar o
# país como Brasil. Deem uma olhada nos resultados e vejam se atende às necessidades do projeto.
# A API permite até 5000 requisições/mês, esse trecho faz 115. Deixei comentado pra não gastar o limite todo.
# Se precisarem, tem mais informações neste link: https://gender-guesser.com/

# Retorna o gênero de cada autor e adiciona a coluna "Gênero" na tabela para armazenar a informação
# nomes = list(autores_citados['Nome'])
# autores_citados['Gênero'] = ''

# for nome in nomes:
#   nome = nome.split()
#   url = 'https://v2.namsor.com/NamSorAPIv2/api2/json/gender/'+nome[0]+'/'+nome[-1]
#   headers = {
#       "X-API-KEY": "a88a2e74053b95262dc88f745124cbfb",
#       "Accept": "application/json"
#       }
#   response = requests.request("GET", url, headers=headers).json()
#   genero = response['likelyGender']
#   autores_citados.loc[autores_citados['Nome'].eq(' '.join(nome)), 'Gênero'] = genero
#   print(nome[0]+ ' ' +nome[-1]+ ': ' +genero)

# print('--- Fim ---')

# Salva uma tabela de nome "autores_citados" no BigQuery.
# Fiz isso pra não ter que ficar rodando o código toda vez

# autores_citados.columns = ['nome', 'posicao', 'doi', 'link_bori', 'genero']
# salva_tabela_bq('autores_citados', autores_citados)

# Commented out IPython magic to ensure Python compatibility.
# # Retorna o nome e o gênero de todos os autores citados
# %%bigquery autores_citados --project=insyspo
# 
# SELECT genero
# FROM userdb_thais_peixoto.autores_citados;

# Conta o número de autores para cada gênero
generos = list(autores_citados['genero'])
genero_quantidade = {'female': 0, 'male': 0}

for genero in generos:
  genero_quantidade[genero] += 1

genero_quantidade = pd.DataFrame(genero_quantidade.items())
genero_quantidade.columns = ['Gênero', 'Nº de autores']
genero_quantidade

fig = px.pie(genero_quantidade,
             values='Nº de autores',
             names='Gênero',
             color_discrete_sequence=[px.colors.qualitative.Set3[5], px.colors.qualitative.Set3[11]],
             title='BORI - Número de autores citados por gênero')
fig.show()

"""# Dashboard"""

# Eu comecei a achar esse notebook meio confuso de navegar conforme mais gráficos foram sendo gerados, então procurei uma forma
# de criar um dashboard para visualizar apenas os gráficos, sem o código. Só não terminei de arrumar ainda

# Funções que geram os gráficos
def numero_percentual_dois():
  fig = px.pie(analise_quantidade,
             values='Quantidade',
             names='Análise',
             color_discrete_sequence=[px.colors.qualitative.Plotly[7], px.colors.qualitative.Plotly[2]],
             title='BORI - Associação press release/DOI')
  return dcc.Graph(figure=fig)

def prs_por_mes():
    fig = px.bar(mes_quantidade_prs,
             x="Nº de publicações",
             y="Mês",
             orientation='h',
             color_discrete_sequence=[px.colors.qualitative.Plotly[4]],
             title='BORI - Número de press releases por mês',
             text_auto=True)
    fig.update_layout(yaxis={'categoryorder':'total ascending'})
    return dcc.Graph(figure=fig)

def dois_por_mes():
    fig = px.bar(mes_quantidade_dois,
             x="Nº de publicações",
             y="Mês",
             orientation='h',
             color_discrete_sequence=[px.colors.qualitative.Plotly[5]],
             title='BORI - Número de DOIs por mês',
             text_auto=True)
    fig.update_layout(yaxis={'categoryorder':'total ascending'})
    return dcc.Graph(figure=fig)

def publicacoes_por_categoria():
    fig = px.bar(categoria_quantidade,
             x="Nº de publicações",
             y="Categoria",
             orientation='h',
             color_discrete_sequence=[px.colors.qualitative.Plotly[6]],
             title='BORI - Número de publicações por categoria',
             text_auto=True)
    fig.update_layout(autosize=False,
                      height=1100,
                      width=1265,
                      yaxis={'categoryorder':'total ascending'})
    return dcc.Graph(figure=fig)

def publicacoes_sobre_covid():
  fig = px.pie(tema_quantidade_df,
             values='Nº de publicações',
             names='Tema',
             color_discrete_sequence=[px.colors.qualitative.Pastel[5], px.colors.qualitative.Pastel[9]],
             title='BORI - Publicações sobre COVID-19')
  return dcc.Graph(figure=fig)

def publicacoes_covid_ano():
    fig = go.Figure(data=[
    go.Bar(name='COVID-19',
           x=ano_tema['Ano'],
           y=ano_tema['COVID-19'],
           marker_color=px.colors.qualitative.Pastel[9],
           text=ano_tema['COVID-19']),
    go.Bar(name='Outros',
           x=ano_tema['Ano'],
           y=ano_tema['Outros'],
           marker_color=px.colors.qualitative.Pastel[5],
           text=ano_tema['Outros'])])
    fig.update_layout(barmode='group',
                      title="Publicações sobre COVID-19 por ano")
    return dcc.Graph(figure=fig)

def publicacoes_indexadas_scielo():
  fig = px.pie(indexacao_quantidade,
             values='Nº de publicações',
             names='Indexação SciELO',
             color_discrete_sequence=[px.colors.qualitative.Pastel1[7], px.colors.qualitative.Set1[7]],
             title='BORI - Publicações indexadas no SciELO')
  return dcc.Graph(figure=fig)

def instituicoes_por_regiao():
    fig = px.bar(regiao_quantidade,
             x="Nº de instituições",
             y="Região",
             orientation='h',
             color_discrete_sequence=[px.colors.qualitative.Plotly[9]],
             title='BORI - Número de instituições por região',
             text_auto=True)
    fig.update_layout(yaxis={'categoryorder':'total ascending'})
    return dcc.Graph(figure=fig)

def publicacoes_area_conhecimento():
    fig = px.bar(bori_areas,
             x="Nº de publicações",
             y="Área do conhecimento",
             orientation='h',
             color_discrete_sequence=[px.colors.qualitative.Pastel1[0]],
             title='BORI - Número de publicações por área do conhecimento',
             text_auto=True)
    fig.update_layout(autosize=False,
                      height=700,
                      width=1265,
                      yaxis={'categoryorder':'total ascending'})
    return dcc.Graph(figure=fig)

def publicacoes_area_geral():
    fig = px.bar(bori_agrupamento,
             x="Nº de publicações",
             y="Área do conhecimento (geral)",
             orientation='h',
             color_discrete_sequence=[px.colors.qualitative.Alphabet[18]],
             title='BORI - Número de publicações por área do conhecimento (geral)',
             text_auto=True)
    fig.update_layout(yaxis={'categoryorder':'total ascending'})
    return dcc.Graph(figure=fig)

def publicacoes_acesso_aberto():
  fig = px.pie(acesso_quantidade,
             values='Nº de publicações',
             names='Tipo de acesso',
             color_discrete_sequence=[px.colors.qualitative.Dark2[0], px.colors.qualitative.Pastel2[0]],
             title='BORI - Número de publicações de acesso aberto')
  return dcc.Graph(figure=fig)

def publicacoes_oa_scielo():
    colors = [px.colors.qualitative.Set3[9],
          px.colors.qualitative.Set3[9],
          px.colors.qualitative.Pastel1[3],
          px.colors.qualitative.Pastel1[3]]

    fig = go.Figure(data=[
        go.Bar(x = bori_comparacao['Nº de publicações'],
               y = bori_comparacao['Análise'],
               orientation='h',
               marker_color=colors,
               text=bori_comparacao['Nº de publicações'])])
    fig.update_layout(yaxis=dict(autorange="reversed"),
                      title='BORI - Publicações de acesso aberto x Publicações indexadas no SciELO')
    return dcc.Graph(figure=fig)

def autores_citados_posicao():
  fig = px.pie(posicao_quantidade,
             values='Nº de autores',
             names='Posição',
             color_discrete_sequence=[px.colors.qualitative.Dark2[4], px.colors.qualitative.Set2[4], px.colors.qualitative.Pastel2[4]],
             title='BORI - Número de autores citados por posição')
  return dcc.Graph(figure=fig)

def autores_citados_genero():
  fig = px.pie(genero_quantidade,
             values='Nº de autores',
             names='Gênero',
             color_discrete_sequence=[px.colors.qualitative.Set3[5], px.colors.qualitative.Set3[11]],
             title='BORI - Número de autores citados por gênero')
  return dcc.Graph(figure=fig)

# Inicialização, configuração e execução do dashboard
app = Dash(__name__)

app.layout = html.Div([
    html.H1('Agência BORI - Análise atualizada'),
    numero_percentual_dois(),
    prs_por_mes(),
    dois_por_mes(),
    publicacoes_por_categoria(),
    publicacoes_sobre_covid(),
    publicacoes_covid_ano(),
    publicacoes_indexadas_scielo(),
    instituicoes_por_regiao(),
    publicacoes_area_conhecimento(),
    publicacoes_area_geral(),
    publicacoes_acesso_aberto(),
    publicacoes_oa_scielo(),
    autores_citados_posicao(),
    autores_citados_genero()
])

if __name__ == '__main__':
    app.run(jupyter_mode='external')